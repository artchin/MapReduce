# Hadoop MapReduce

Распределённая обработка больших данных с использованием парадигмы MapReduce.

## Задачи

### 1. Random ID Shuffle
Перемешивание списка идентификаторов в случайном порядке с группировкой 1-5 ID в строке.

**Алгоритм:**
- Присвоение случайного ключа каждому ID
- Распределённая сортировка по ключу
- Группировка со случайным размером batch

### 2. Bigram Document Frequency
Подсчёт пар слов (биграмм), встречающихся в наибольшем числе документов Wikipedia (4000+ статей).

**Этапы обработки:**
- Очистка от пунктуации (`regex [^A-Za-z\\s]`)
- Приведение к нижнему регистру
- Подсчёт уникальных документов для каждой биграммы
- Сортировка по частоте и лексикографически

## Stack

| Технология | Назначение |
|------------|------------|
| Hadoop HDFS | Распределённое хранение данных |
| Hadoop YARN | Управление ресурсами кластера |
| Hadoop MapReduce | Распределённые вычисления |
| Python Streaming API | Реализация mapper/reducer |
| RegEx | Очистка и парсинг текста |

## Результаты

- Оптимизация числа Job'ов и Reducer'ов
- Минимизация времени обработки на кластере
- Код проверен тестами преподавателей ШАД (7-8 тестов на задачу)
